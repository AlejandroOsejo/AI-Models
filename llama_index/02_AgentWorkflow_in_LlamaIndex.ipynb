{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f33f21f",
   "metadata": {},
   "source": [
    "### FunctionAgent / AgentWorkflow\n",
    "\n",
    "The AgentWorkflow is an orchestrator for running a system of one or more agents. In this example, we'll create a simple workflow with a single FunctionAgent, and use that to cover the basic functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbed2f0",
   "metadata": {},
   "source": [
    "Versions\n",
    "Llama index 0.12.31\n",
    "Python 3.11.9 others can be used this is the one im using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "613edbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.12.31)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.4.6)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.31 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.12.31)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.6.11)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.3.37)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.4.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.4.7)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.75.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.31->llama-index) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (3.11.16)\n",
      "Requirement already satisfied: banks<3.0.0,>=2.0.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (2.1.1)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (2025.3.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (2.2.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (2.11.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index) (1.17.2)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.18)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.4.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.12)\n",
      "Requirement already satisfied: click in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.31->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.31->llama-index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.31->llama-index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.31->llama-index) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.31->llama-index) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.31->llama-index) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.31->llama-index) (1.20.0)\n",
      "Requirement already satisfied: griffe in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.31->llama-index) (1.7.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.31->llama-index) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.31->llama-index) (4.3.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.7)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
      "Requirement already satisfied: anyio in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.31->llama-index) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.31->llama-index) (1.0.8)\n",
      "Requirement already satisfied: idna in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.31->llama-index) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.31->llama-index) (0.14.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.12 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.12)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.31->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.31->llama-index) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.31->llama-index) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.31->llama-index) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.31->llama-index) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.31->llama-index) (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.31->llama-index) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.31->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.31->llama-index) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-cloud-services>=0.6.12->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.31->llama-index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.31->llama-index) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb96cee",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e8102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tavily-python in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: requests in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tavily-python) (2.32.3)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tavily-python) (0.9.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tavily-python) (0.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->tavily-python) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->tavily-python) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->tavily-python) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->tavily-python) (2025.1.31)\n",
      "Requirement already satisfied: anyio in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->tavily-python) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->tavily-python) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from anyio->httpx->tavily-python) (4.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-together in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-together) (0.12.31)\n",
      "Requirement already satisfied: llama-index-llms-openai-like<0.4.0,>=0.3.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-together) (0.3.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (3.11.16)\n",
      "Requirement already satisfied: banks<3.0.0,>=2.0.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (2.1.1)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (2025.3.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (2.2.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (2.11.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (1.17.2)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.9 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-together) (0.3.37)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-together) (4.51.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (1.20.0)\n",
      "Requirement already satisfied: griffe in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (1.7.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (4.3.7)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.66.3 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-together) (1.75.0)\n",
      "Requirement already satisfied: click in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-together) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-together) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-together) (24.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-together) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-together) (0.5.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (3.26.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.66.3->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-together) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.66.3->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-together) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.66.3->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-together) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-together) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (2.11.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\juans\\appdata\\roaming\\python\\python311\\site-packages (from groq) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\juans\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install groq\n",
    "%pip install -Uq llama-index-llms-groq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e581bd5d",
   "metadata": {},
   "source": [
    "For this example, we will use Groq as our LLM can be replaced by OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9130d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "llm = Groq(\n",
    "    model=\"llama3-70b-8192\",  # o el modelo que prefieras, como llama3-8b\n",
    "    api_key=\"Groq API KEY\"           # tu API Key de Groq\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52288418",
   "metadata": {},
   "source": [
    "To make our agent more useful, we can give it tools/actions to use. In this case, we'll use Tavily to implement a tool that can search the web for information. You can get a free API key from Tavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e95e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb9b96f",
   "metadata": {},
   "source": [
    "\n",
    "When creating a tool, its very important to:\n",
    "\n",
    "give the tool a proper name and docstring/description. The LLM uses this to understand what the tool does.\n",
    "annotate the types. This helps the LLM understand the expected input and output types.\n",
    "use async when possible, since this will make the workflow more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9072bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import AsyncTavilyClient\n",
    "\n",
    "async def search_web(query: str) -> str:\n",
    "    \"\"\"Useful for using the web to answer questions.\"\"\"\n",
    "    client = AsyncTavilyClient(api_key=\"Tavily API KEY\")\n",
    "    return str(await client.search(query))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570d61fd",
   "metadata": {},
   "source": [
    "With the tool and and LLM defined, we can create an AgentWorkflow that uses the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e1a604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "\n",
    "agent = FunctionAgent(\n",
    "    tools=[search_web],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that can search the web for information.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805cb2d",
   "metadata": {},
   "source": [
    "## Running the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b25df1",
   "metadata": {},
   "source": [
    "Now that our agent is created, we can run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0388294b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in San Francisco is 13.2°C (55.8°F) with mist, and a feelslike temperature of 12.0°C (53.5°F).\n"
     ]
    }
   ],
   "source": [
    "response = await workflow.run(user_msg=\"What is the weather in San Francisco?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e126db5",
   "metadata": {},
   "source": [
    "The above is the equivalent of the following of using AgentWorkflow with a single FunctionAgent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98c46203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "\n",
    "workflow = AgentWorkflow(agents=[agent])\n",
    "\n",
    "response = await workflow.run(user_msg=\"What is the weather in San Francisco?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b085ad",
   "metadata": {},
   "source": [
    "## Maintaining State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4121d0f",
   "metadata": {},
   "source": [
    "By default, the FunctionAgent will maintain stateless between runs. This means that the agent will not have any memory of previous runs.\n",
    "\n",
    "To maintain state, we need to keep track of the previous state. Since the FunctionAgent is running in a Workflow, the state is stored in the Context. This can be passed between runs to maintain state and history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "538365f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems like the tool has provided a list of search results related to the name \"Logan\". From the results, I can see that there are multiple references to the movie \"Logan\" (2017) starring Hugh Jackman as Wolverine, as well as some information about the character Logan from the X-Men franchise. If you're looking for more specific information about Logan, could you please clarify what you're interested in knowing?\n",
      "I remember! Your name is Logan.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "ctx = Context(agent)\n",
    "\n",
    "response = await agent.run(user_msg=\"My name is Logan\", ctx=ctx)\n",
    "print(str(response))\n",
    "\n",
    "response = await agent.run(user_msg=\"What is my name?\", ctx=ctx)\n",
    "print(str(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507cd7dd",
   "metadata": {},
   "source": [
    "\n",
    "The context is serializable, so it can be saved to a database, file, etc. and loaded back in later.\n",
    "\n",
    "The JsonSerializer is a simple serializer that uses json.dumps and json.loads to serialize and deserialize the context.\n",
    "\n",
    "The JsonPickleSerializer is a serializer that uses pickle to serialize and deserialize the context. If you have objects in your context that are not serializable, you can use this serializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f48aad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I remember! Your name is Logan.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import JsonSerializer\n",
    "\n",
    "ctx_dict = ctx.to_dict(serializer=JsonSerializer())\n",
    "restored_ctx = Context.from_dict(agent, ctx_dict, serializer=JsonSerializer())\n",
    "\n",
    "response = await agent.run(user_msg=\"Do you remember my name?\", ctx=restored_ctx)\n",
    "print(str(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d248362",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb27ba9b",
   "metadata": {},
   "source": [
    "The AgentWorkflow/FunctionAgent also supports streaming. Since the AgentWorkflow is a Workflow, it can be streamed like any other Workflow. This works by using the handler that is returned from the workflow. There are a few key events that are streamed, feel free to explore below.\n",
    "\n",
    "If you only want to stream the LLM output, you can use the AgentStream events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa967839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Saskatoon is 4.3°C (39.7°F) with light rain, and a wind speed of 24.5 km/h (15.2 mph) from the northeast. The humidity is 93%, and the windchill is -0.3°C (31.4°F)."
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    AgentInput,\n",
    "    AgentOutput,\n",
    "    ToolCall,\n",
    "    ToolCallResult,\n",
    "    AgentStream,\n",
    ")\n",
    "\n",
    "handler = agent.run(user_msg=\"What is the weather in Saskatoon?\")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, AgentStream):\n",
    "        print(event.delta, end=\"\", flush=True)\n",
    "        # print(event.response)  # the current full response\n",
    "        # print(event.raw)  # the raw llm api response\n",
    "        # print(event.current_agent_name)  # the current agent name\n",
    "    # elif isinstance(event, AgentInput):\n",
    "    #    print(event.input)  # the current input messages\n",
    "    #    print(event.current_agent_name)  # the current agent name\n",
    "    # elif isinstance(event, AgentOutput):\n",
    "    #    print(event.response)  # the current full response\n",
    "    #    print(event.tool_calls)  # the selected tool calls, if any\n",
    "    #    print(event.raw)  # the raw llm api response\n",
    "    # elif isinstance(event, ToolCallResult):\n",
    "    #    print(event.tool_name)  # the tool name\n",
    "    #    print(event.tool_kwargs)  # the tool kwargs\n",
    "    #    print(event.tool_output)  # the tool output\n",
    "    # elif isinstance(event, ToolCall):\n",
    "    #     print(event.tool_name)  # the tool name\n",
    "    #     print(event.tool_kwargs)  # the tool kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45227a4",
   "metadata": {},
   "source": [
    "## Tools and State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aefb8b",
   "metadata": {},
   "source": [
    "Tools can also be defined that have access to the workflow context. This means you can set and retrieve variables from the context and use them in the tool or between tools.\n",
    "\n",
    "Note: The Context parameter should be the first parameter of the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2cf0447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: {'name': 'Logan'}\n",
      "\n",
      "Current message:\n",
      "Logan\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "\n",
    "async def set_name(ctx: Context, name: str) -> str:\n",
    "    state = await ctx.get(\"state\")\n",
    "    state[\"name\"] = name\n",
    "    await ctx.set(\"state\", state)\n",
    "    return f\"Name set to {name}\"\n",
    "\n",
    "\n",
    "agent = AgentWorkflow(\n",
    "    agents=[\n",
    "        FunctionAgent(\n",
    "            tools=[set_name],\n",
    "            llm=llm,\n",
    "            system_prompt=\"You are a helpful assistant that can set a name.\",\n",
    "        )\n",
    "    ],\n",
    "    initial_state={\"name\": \"unset\"},\n",
    ")\n",
    "\n",
    "ctx = Context(agent)\n",
    "\n",
    "response = await agent.run(user_msg=\"My name is Logan\", ctx=ctx)\n",
    "print(str(response))\n",
    "\n",
    "state = await ctx.get(\"state\")\n",
    "print(state[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17571e4e",
   "metadata": {},
   "source": [
    "## Human in the Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c16259",
   "metadata": {},
   "source": [
    "Tools can also be defined that involve a human in the loop. This is useful for tasks that require human input, such as confirming a tool call or providing feedback.\n",
    "\n",
    "Using workflow events, we can emit events that require a response from the user. Here, we use the built-in InputRequiredEvent and HumanResponseEvent to handle the human in the loop, but you can also define your own events.\n",
    "\n",
    "wait_for_event will emit the waiter_event and wait until it sees the HumanResponseEvent with the specified requirements. The waiter_id is used to ensure that we only send one waiter_event for each waiter_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c530200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Context,\n",
    "    InputRequiredEvent,\n",
    "    HumanResponseEvent,\n",
    ")\n",
    "\n",
    "\n",
    "async def dangerous_task(ctx: Context) -> str:\n",
    "    \"\"\"A dangerous task that requires human confirmation.\"\"\"\n",
    "\n",
    "    question = \"Are you sure you want to proceed?\"\n",
    "    response = await ctx.wait_for_event(\n",
    "        HumanResponseEvent,\n",
    "        waiter_id=question,\n",
    "        waiter_event=InputRequiredEvent(\n",
    "            prefix=question,\n",
    "            user_name=\"Logan\",\n",
    "        ),\n",
    "        requirements={\"user_name\": \"Logan\"},\n",
    "    )\n",
    "    if response.response == \"yes\":\n",
    "        return \"Dangerous task completed successfully.\"\n",
    "    else:\n",
    "        return \"Dangerous task aborted.\"\n",
    "\n",
    "\n",
    "agent = FunctionAgent(\n",
    "    tools=[dangerous_task],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that can perform dangerous tasks.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0170a03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dangerous task has been completed successfully.\n"
     ]
    }
   ],
   "source": [
    "handler = agent.run(user_msg=\"I want to proceed with the dangerous task.\")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, InputRequiredEvent):\n",
    "        response = input(event.prefix).strip().lower()\n",
    "        handler.ctx.send_event(\n",
    "            HumanResponseEvent(\n",
    "                response=response,\n",
    "                user_name=event.user_name,\n",
    "            )\n",
    "        )\n",
    "\n",
    "response = await handler\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e41d2f",
   "metadata": {},
   "source": [
    "In production scenarios, you might handle human-in-the-loop over a websocket or multiple API requests.\n",
    "\n",
    "As mentioned before, the Context object is serializable, and this means we can also save the workflow mid-run and restore it later.\n",
    "\n",
    "NOTE: Any functions/steps that were in-progress will start from the beginning when the workflow is restored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56df8a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dangerous task has been completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import JsonSerializer\n",
    "\n",
    "handler = agent.run(user_msg=\"I want to proceed with the dangerous task.\")\n",
    "\n",
    "input_ev = None\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, InputRequiredEvent):\n",
    "        input_ev = event\n",
    "        break\n",
    "\n",
    "# save the context somewhere for later\n",
    "ctx_dict = handler.ctx.to_dict(serializer=JsonSerializer())\n",
    "\n",
    "# get the response from the user\n",
    "response_str = input(input_ev.prefix).strip().lower()\n",
    "\n",
    "# restore the workflow\n",
    "restored_ctx = Context.from_dict(agent, ctx_dict, serializer=JsonSerializer())\n",
    "\n",
    "handler = agent.run(ctx=restored_ctx)\n",
    "handler.ctx.send_event(\n",
    "    HumanResponseEvent(\n",
    "        response=response_str,\n",
    "        user_name=input_ev.user_name,\n",
    "    )\n",
    ")\n",
    "response = await handler\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
